{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "mhpkWSYAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Siteng Huang", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=mhpkWSYAAAAJ&citpid=1", "affiliation": "Alibaba DAMO Academy | ZJU | Westlake University", "interests": ["Embodied AI", "Vision-language Models", "Generative Models"], "email_domain": "@westlake.edu.cn", "homepage": "https://kyonhuang.top/", "citedby": 1721, "publications": {"mhpkWSYAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "DSANet: Dual Self-Attention Network for Multivariate Time Series Forecasting", "pub_year": "2019"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:u-x6o8ySG0sC", "num_citations": 377, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12980008905395258594", "cites_id": ["12980008905395258594"]}, "mhpkWSYAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Pareto Self-Supervised Training for Few-Shot Learning", "pub_year": "2021"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:2osOgNQ5qMEC", "num_citations": 166, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2504568909812331056", "cites_id": ["2504568909812331056"]}, "mhpkWSYAAAAJ:Se3iqnhoufwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Cobra: Extending Mamba to Multi-Modal Large Language Model for Efficient Inference", "pub_year": "2024"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:Se3iqnhoufwC", "num_citations": 122, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15534377507885297258", "cites_id": ["15534377507885297258"]}, "mhpkWSYAAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Prompt-Based Distribution Alignment for Unsupervised Domain Adaptation", "pub_year": "2024"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:roLk4NBRz8UC", "num_citations": 105, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=503058469274235467", "cites_id": ["503058469274235467"]}, "mhpkWSYAAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VoP: Text-Video Co-operative Prompt Tuning for Cross-Modal Retrieval", "pub_year": "2023"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:W7OEmFMy1HYC", "num_citations": 100, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2078328731208560008", "cites_id": ["2078328731208560008"]}, "mhpkWSYAAAAJ:9ZlFYXVOiuMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "WorldVLA: Towards Autoregressive Action World Model", "pub_year": "2025"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:9ZlFYXVOiuMC", "num_citations": 74, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15619447321127946082", "cites_id": ["15619447321127946082"]}, "mhpkWSYAAAAJ:3fE2CSJIrl8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "QUAR-VLA: Vision-Language-Action Model for Quadruped Robots", "pub_year": "2024"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:3fE2CSJIrl8C", "num_citations": 69, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5507416174529306602", "cites_id": ["5507416174529306602"]}, "mhpkWSYAAAAJ:Zph67rFs4hoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Accelerating Diffusion Transformers with Token-wise Feature Caching", "pub_year": "2024"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:Zph67rFs4hoC", "num_citations": 60, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9696062613102340406", "cites_id": ["9696062613102340406"]}, "mhpkWSYAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Troika: Multi-Path Cross-Modal Traction for Compositional Zero-Shot Learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:eQOLeE2rZwMC", "num_citations": 57, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7037692838184369503", "cites_id": ["7037692838184369503"]}, "mhpkWSYAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Attributes-Guided and Pure-Visual Attention Alignment for Few-Shot Recognition", "pub_year": "2021"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:9yKSN-GCB0IC", "num_citations": 50, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13687905282541047466", "cites_id": ["13687905282541047466"]}, "mhpkWSYAAAAJ:4DMP91E08xMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "OpenHelix: A Short Survey, Empirical Analysis, and Open-Source Dual-System VLA Model for Robotic Manipulation", "pub_year": "2025"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:4DMP91E08xMC", "num_citations": 48, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11309378623933549376", "cites_id": ["11309378623933549376"]}, "mhpkWSYAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Tree Structure-Aware Few-Shot Image Classification via Hierarchical Aggregation", "pub_year": "2022"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:Tyk-4Ss8FVUC", "num_citations": 44, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7260005370926286580", "cites_id": ["7260005370926286580"]}, "mhpkWSYAAAAJ:4TOpqqG69KYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Humanoid-VLA: Towards Universal Humanoid Control with Visual Integration", "pub_year": "2025"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:4TOpqqG69KYC", "num_citations": 42, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17195962855460759079", "cites_id": ["17195962855460759079"]}, "mhpkWSYAAAAJ:L8Ckcad2t8MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model", "pub_year": "2025"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:L8Ckcad2t8MC", "num_citations": 35, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1874017201288359298", "cites_id": ["1874017201288359298"]}, "mhpkWSYAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning Disentangled Identifiers for Action-Customized Text-to-Image Generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:_FxGoFyzp5QC", "num_citations": 30, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13026574760311232203", "cites_id": ["13026574760311232203"]}, "mhpkWSYAAAAJ:KlAtU1dfN6UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Filter, Correlate, Compress: Training-Free Token Reduction for MLLM Acceleration", "pub_year": "2024"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:KlAtU1dfN6UC", "num_citations": 28, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8794276652755652230,11400262616627503782", "cites_id": ["8794276652755652230", "11400262616627503782"]}, "mhpkWSYAAAAJ:_kc_bZDykSQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Global Compression Commander: Plug-and-Play Inference Acceleration for High-Resolution Large Vision-Language Models", "pub_year": "2025"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:_kc_bZDykSQC", "num_citations": 27, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6145777281003963452,12847056739468876881", "cites_id": ["6145777281003963452", "12847056739468876881"]}, "mhpkWSYAAAAJ:ULOm3_A8WrAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "CARP: Visuomotor Policy Learning via Coarse-to-Fine Autoregressive Prediction", "pub_year": "2024"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:ULOm3_A8WrAC", "num_citations": 26, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9725474775895739036", "cites_id": ["9725474775895739036"]}, "mhpkWSYAAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Check, Locate, Rectify: A Training-Free Layout Calibration System for Text-to-Image Generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:LkGwnXOMwfcC", "num_citations": 26, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7969290129947561026", "cites_id": ["7969290129947561026"]}, "mhpkWSYAAAAJ:qxL8FJ1GzNcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Exploring the Evolution of Physics Cognition in Video Generation: A Survey", "pub_year": "2025"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:qxL8FJ1GzNcC", "num_citations": 22, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15910608076547540994", "cites_id": ["15910608076547540994"]}, "mhpkWSYAAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VGDIFFZERO: Text-To-Image Diffusion Models Can Be Zero-Shot Visual Grounders", "pub_year": "2024"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:ufrVoPGSRksC", "num_citations": 21, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8687101331233228541", "cites_id": ["8687101331233228541"]}, "mhpkWSYAAAAJ:Wp0gIr-vW9MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SSR: Enhancing Depth Perception in Vision-Language Models via Rationale-Guided Spatial Reasoning", "pub_year": "2025"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:Wp0gIr-vW9MC", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8227291448795067898", "cites_id": ["8227291448795067898"]}, "mhpkWSYAAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Sparse-Tuning: Adapting Vision Transformers with Efficient Fine-tuning and Inference", "pub_year": "2024"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:hqOjcs7Dif8C", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2242206580160713443", "cites_id": ["2242206580160713443"]}, "mhpkWSYAAAAJ:kNdYIx-mwKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "M2IST: Multi-Modal Interactive Side-Tuning for Efficient Referring Expression Comprehension", "pub_year": "2025"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:kNdYIx-mwKoC", "num_citations": 18, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3301366871514887654,9233564457725493744", "cites_id": ["3301366871514887654", "9233564457725493744"]}, "mhpkWSYAAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "DARA: Domain-and Relation-aware Adapters Make Parameter-efficient Tuning for Visual Grounding", "pub_year": "2024"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:UebtZRa9Y70C", "num_citations": 18, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14132004256576852880", "cites_id": ["14132004256576852880"]}, "mhpkWSYAAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Domain Generalized Few-Shot Image Classification via Meta Regularization Network", "pub_year": "2022"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:zYLM7Y9cAGgC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9714452223899196924", "cites_id": ["9714452223899196924"]}, "mhpkWSYAAAAJ:ZeXyd9-uunAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation", "pub_year": "2025"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:ZeXyd9-uunAC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13908774117819003084", "cites_id": ["13908774117819003084"]}, "mhpkWSYAAAAJ:5nxA0vEk-isC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ProFD: Prompt-Guided Feature Disentangling for Occluded Person Re-Identification", "pub_year": "2024"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:5nxA0vEk-isC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11784894708145253260", "cites_id": ["11784894708145253260"]}, "mhpkWSYAAAAJ:YOwf2qJgpHMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "QUART-Online: Latency-Free Large Multimodal Language Model for Quadruped Robot Learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:YOwf2qJgpHMC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14873456552705273419,415974777769746733", "cites_id": ["14873456552705273419", "415974777769746733"]}, "mhpkWSYAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "HINFShot: A Challenge Dataset for Few-Shot Node Classification in Heterogeneous Information Network", "pub_year": "2021"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:UeHWp8X0CEIC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3090730080803330872", "cites_id": ["3090730080803330872"]}, "mhpkWSYAAAAJ:IWHjjKOFINEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation", "pub_year": "2025"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:IWHjjKOFINEC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17936190881432832961", "cites_id": ["17936190881432832961"]}, "mhpkWSYAAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Reference-Limited Compositional Zero-Shot Learning", "pub_year": "2023"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:Y0pCki6q_DkC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8782448089053948333", "cites_id": ["8782448089053948333"]}, "mhpkWSYAAAAJ:mB3voiENLucC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Variation-aware Vision Token Dropping for Faster Large Vision-Language Models", "pub_year": "2025"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:mB3voiENLucC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17060474890180189664", "cites_id": ["17060474890180189664"]}, "mhpkWSYAAAAJ:M3ejUd6NZC8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Score and Distribution Matching Policy: Advanced Accelerated Visuomotor Policies via Matched Distillation", "pub_year": "2024"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:M3ejUd6NZC8C", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4270099371666686154", "cites_id": ["4270099371666686154"]}, "mhpkWSYAAAAJ:MXK_kJrjxJIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PiTe: Pixel-Temporal Alignment for Large Video-Language Model", "pub_year": "2024"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:MXK_kJrjxJIC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7685950899240310497", "cites_id": ["7685950899240310497"]}, "mhpkWSYAAAAJ:aqlVkmm33-oC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Unicorn: Text-only data synthesis for vision language model training", "pub_year": "2025"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:aqlVkmm33-oC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17718942577270488132", "cites_id": ["17718942577270488132"]}, "mhpkWSYAAAAJ:hC7cP41nSMkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "RynnVLA-002: A Unified Vision-Language-Action and World Model", "pub_year": "2025"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:hC7cP41nSMkC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7641453366133280732", "cites_id": ["7641453366133280732"]}, "mhpkWSYAAAAJ:qUcmZB5y_30C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "High-Fidelity Simulated Data Generation for Real-World Zero-Shot Robotic Manipulation Learning with Gaussian Splatting", "pub_year": "2025"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:qUcmZB5y_30C", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14879931717119873792", "cites_id": ["14879931717119873792"]}, "mhpkWSYAAAAJ:dhFuZR0502QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors", "pub_year": "2025"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:dhFuZR0502QC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15289803919451818857", "cites_id": ["15289803919451818857"]}, "mhpkWSYAAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Focus-Consistent Multi-Level Aggregation for Compositional Zero-Shot Learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:8k81kl-MbHgC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6655773590544011508", "cites_id": ["6655773590544011508"]}, "mhpkWSYAAAAJ:-f6ydRqryjwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "HiF-VLA: Hindsight, Insight and Foresight through Motion Representation for Vision-Language-Action Models", "pub_year": "2025"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:-f6ydRqryjwC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6074428916759666483", "cites_id": ["6074428916759666483"]}, "mhpkWSYAAAAJ:mVmsd5A6BfQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VARD: Efficient and Dense Fine-Tuning for Diffusion Models with Value-based RL", "pub_year": "2025"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:mVmsd5A6BfQC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14445282673936744448", "cites_id": ["14445282673936744448"]}, "mhpkWSYAAAAJ:hFOr9nPyWt4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MAPGD: Multi-Agent Prompt Gradient Descent for Collaborative Prompt Optimization", "pub_year": "2025"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:hFOr9nPyWt4C", "num_citations": 0}, "mhpkWSYAAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VoP: Text-Video Co-operative Prompt Tuning for Cross-Modal Retrieval Supplementary Material"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:WF5omc3nYNoC", "num_citations": 0}, "mhpkWSYAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Supplement Material: Pareto Self-Supervised Training for Few-Shot Learning"}, "filled": false, "author_pub_id": "mhpkWSYAAAAJ:qjMakFHDy7sC", "num_citations": 0}}, "citedby5y": 1708, "hindex": 21, "hindex5y": 21, "i10index": 30, "i10index5y": 30, "cites_per_year": {"2020": 13, "2021": 48, "2022": 111, "2023": 170, "2024": 349, "2025": 937, "2026": 93}, "updated": "2026-02-13 12:24:44.058587"}